[2023-05-07T03:19:20.238+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:19:20.299+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:19:20.303+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:19:20.305+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T03:19:20.307+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:19:20.444+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_9-16> on 2022-05-01 00:00:00+00:00
[2023-05-07T03:19:20.533+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_9-16', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2654', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmpi9calbk8']
[2023-05-07T03:19:20.548+0000] {standard_task_runner.py:83} INFO - Job 2654: Subtask scrape_teams_9-16
[2023-05-07T03:19:20.509+0000] {standard_task_runner.py:55} INFO - Started process 1056 to run task
[2023-05-07T03:19:20.902+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T03:19:21.232+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_9-16
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T03:19:21.249+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
TypeError: scrape_and_save() missing 1 required positional argument: 'current_date'
[2023-05-07T03:19:21.332+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_9-16, execution_date=20220501T000000, start_date=20230507T031920, end_date=20230507T031921
[2023-05-07T03:19:21.385+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2654 for task scrape_teams_9-16 (scrape_and_save() missing 1 required positional argument: 'current_date'; 1056)
[2023-05-07T03:19:21.543+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-07T03:19:21.697+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T03:21:44.045+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:21:44.186+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:21:44.189+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:21:44.191+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T03:21:44.192+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:21:44.436+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_9-16> on 2022-05-01 00:00:00+00:00
[2023-05-07T03:21:44.490+0000] {standard_task_runner.py:55} INFO - Started process 1439 to run task
[2023-05-07T03:21:44.581+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_9-16', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2762', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp9f_i9peo']
[2023-05-07T03:21:44.620+0000] {standard_task_runner.py:83} INFO - Job 2762: Subtask scrape_teams_9-16
[2023-05-07T03:21:45.294+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T03:21:45.546+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T03:21:46.001+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_9-16
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T03:21:47.342+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T03:21:47.397+0000] {helpers.py:86} INFO - Detroit Pistons: Successfully scraped!
[2023-05-07T03:21:48.290+0000] {helpers.py:86} INFO - Golden State Warriors: Successfully scraped!
[2023-05-07T03:21:48.690+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:48.691+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:48.692+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:21:50.031+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:50.033+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:50.033+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:21:51.205+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:51.206+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:51.207+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:21:52.352+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:52.355+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:52.356+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:21:53.512+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:53.513+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:53.514+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:21:54.666+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:54.667+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:54.668+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:21:56.003+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:56.004+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:56.006+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:21:57.162+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:57.163+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:57.164+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:21:58.308+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:58.310+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:58.310+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:21:59.479+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:59.480+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:59.481+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:00.633+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:00.634+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:00.635+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:01.782+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:01.784+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:01.785+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:22:03.131+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:03.139+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:03.140+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:22:04.298+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:04.299+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:04.300+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:22:05.456+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:05.457+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:05.460+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:22:06.604+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:06.605+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:06.605+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:22:07.782+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:07.783+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:07.786+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:22:08.962+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:08.963+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:08.972+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:22:10.143+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:10.145+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:10.155+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:22:11.295+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:11.296+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:11.296+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:22:12.442+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:12.443+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:12.444+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:13.807+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:13.809+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:13.810+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:15.150+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:15.152+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:15.154+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:22:16.319+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:16.320+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:16.326+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:22:17.685+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:17.686+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:17.688+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:22:19.003+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:19.010+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:19.012+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:22:20.175+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:20.181+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:20.213+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:22:21.366+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:21.367+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:21.368+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:22:22.551+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:22.553+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:22.553+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:22:23.700+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:23.701+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:23.702+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:22:24.884+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:24.885+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:24.886+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:22:26.064+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:26.066+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:26.066+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:27.232+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:27.242+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:27.243+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:28.603+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:28.604+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:28.606+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:22:29.763+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:29.764+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:29.765+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:22:31.029+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:31.071+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:31.073+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:22:32.286+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:32.292+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:32.296+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:22:33.448+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:33.474+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:33.476+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:22:34.886+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:34.906+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:34.922+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:22:36.277+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:36.278+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:36.279+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:22:37.473+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:37.474+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:37.475+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:22:38.624+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:38.626+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:38.627+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:22:39.778+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:39.783+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:39.784+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:40.939+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:40.942+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:40.948+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:42.322+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:42.357+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:42.358+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:22:43.541+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:43.542+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:43.543+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:22:44.694+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:44.696+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:44.697+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:22:45.846+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:45.870+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:45.872+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:22:47.061+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:47.068+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:47.072+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:22:48.249+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:48.250+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:48.253+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:22:49.603+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:49.605+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:49.606+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:22:50.809+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:50.810+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:50.812+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:22:51.962+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:51.966+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:51.967+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:22:53.116+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:53.118+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:53.119+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:54.299+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:54.300+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:54.303+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:55.693+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:55.697+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:55.699+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:22:57.207+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:57.208+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:57.210+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:22:58.601+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:58.603+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:58.614+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:22:59.827+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:59.828+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:59.829+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:23:01.171+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:01.172+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:01.172+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:23:02.325+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:02.326+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:02.327+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:23:03.490+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:03.491+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:03.492+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:23:04.647+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:04.650+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:04.651+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:23:05.808+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:05.808+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:05.810+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:23:06.971+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:06.972+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:06.973+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:23:08.139+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:08.139+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:23:08.141+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:23:09.204+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_9-16.csv
[2023-05-07T03:23:09.207+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-05-07T03:23:09.250+0000] {taskinstance.py:1332} INFO - Marking task as SUCCESS. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_9-16, execution_date=20220501T000000, start_date=20230507T032144, end_date=20230507T032309
[2023-05-07T03:23:09.366+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-05-07T03:23:09.440+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T03:38:06.025+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:38:06.035+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:38:06.037+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:38:06.039+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T03:38:06.040+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:38:06.061+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_9-16> on 2022-05-01 00:00:00+00:00
[2023-05-07T03:38:06.068+0000] {standard_task_runner.py:55} INFO - Started process 242 to run task
[2023-05-07T03:38:06.080+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_9-16', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2828', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp6vy4wsk1']
[2023-05-07T03:38:06.084+0000] {standard_task_runner.py:83} INFO - Job 2828: Subtask scrape_teams_9-16
[2023-05-07T03:38:06.207+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T03:38:06.245+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T03:38:06.304+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_9-16
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T03:38:07.200+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T03:38:07.224+0000] {helpers.py:86} INFO - Detroit Pistons: Successfully scraped!
[2023-05-07T03:38:07.990+0000] {helpers.py:86} INFO - Golden State Warriors: Successfully scraped!
[2023-05-07T03:38:09.721+0000] {helpers.py:86} INFO - Houston Rockets: Successfully scraped!
[2023-05-07T03:38:10.768+0000] {helpers.py:86} INFO - Indiana Pacers: Successfully scraped!
[2023-05-07T03:38:13.385+0000] {helpers.py:86} INFO - Los Angeles Clippers: Successfully scraped!
[2023-05-07T03:38:14.535+0000] {helpers.py:86} INFO - Los Angeles Lakers: Successfully scraped!
[2023-05-07T03:38:15.136+0000] {helpers.py:86} INFO - Memphis Grizzlies: Successfully scraped!
[2023-05-07T03:38:15.867+0000] {helpers.py:86} INFO - Miami Heat: Successfully scraped!
[2023-05-07T03:38:15.872+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_9-16.csv
[2023-05-07T03:38:15.874+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-05-07T03:38:15.885+0000] {taskinstance.py:1332} INFO - Marking task as SUCCESS. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_9-16, execution_date=20220501T000000, start_date=20230507T033806, end_date=20230507T033815
[2023-05-07T03:38:15.944+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-05-07T03:38:15.966+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T05:14:58.852+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T05:14:58.877+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T05:14:58.878+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T05:14:58.880+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T05:14:58.884+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T05:14:58.921+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_9-16> on 2022-05-01 00:00:00+00:00
[2023-05-07T05:14:58.941+0000] {standard_task_runner.py:55} INFO - Started process 2188 to run task
[2023-05-07T05:14:58.960+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_9-16', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2892', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp076f03xu']
[2023-05-07T05:14:58.966+0000] {standard_task_runner.py:83} INFO - Job 2892: Subtask scrape_teams_9-16
[2023-05-07T05:14:59.150+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T05:14:59.218+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T05:14:59.320+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_9-16
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T05:15:00.216+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T05:15:00.224+0000] {helpers.py:86} INFO - Detroit Pistons: Successfully scraped!
[2023-05-07T05:15:01.536+0000] {helpers.py:86} INFO - Golden State Warriors: Successfully scraped!
[2023-05-07T05:15:02.029+0000] {helpers.py:86} INFO - Houston Rockets: Successfully scraped!
[2023-05-07T05:15:04.439+0000] {helpers.py:86} INFO - Indiana Pacers: Successfully scraped!
[2023-05-07T05:15:05.610+0000] {helpers.py:86} INFO - Los Angeles Clippers: Successfully scraped!
[2023-05-07T05:15:06.805+0000] {helpers.py:86} INFO - Los Angeles Lakers: Successfully scraped!
[2023-05-07T05:15:07.622+0000] {helpers.py:86} INFO - Memphis Grizzlies: Successfully scraped!
[2023-05-07T05:15:07.932+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:07.966+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:07.967+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T05:15:09.312+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:09.313+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:09.315+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T05:15:10.483+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:10.484+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:10.485+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T05:15:11.818+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:11.820+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:11.822+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T05:15:12.974+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:12.975+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:12.978+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T05:15:14.308+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:14.310+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:14.313+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T05:15:15.558+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:15.559+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:15.560+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T05:15:16.748+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:16.749+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:16.751+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T05:15:17.907+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:17.910+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:17.911+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T05:15:19.112+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:19.116+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:19.125+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T05:15:20.407+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:20.408+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:20.418+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T05:15:21.432+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_9-16.csv
[2023-05-07T05:15:21.434+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-05-07T05:15:21.454+0000] {taskinstance.py:1332} INFO - Marking task as SUCCESS. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_9-16, execution_date=20220501T000000, start_date=20230507T051458, end_date=20230507T051521
[2023-05-07T05:15:21.521+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-05-07T05:15:21.571+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T15:15:02.338+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:15:02.353+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:15:02.355+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:15:02.357+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T15:15:02.358+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:15:02.373+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_9-16> on 2022-05-01 00:00:00+00:00
[2023-05-07T15:15:02.385+0000] {standard_task_runner.py:55} INFO - Started process 3129 to run task
[2023-05-07T15:15:02.398+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_9-16', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2968', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmplkg365al']
[2023-05-07T15:15:02.403+0000] {standard_task_runner.py:83} INFO - Job 2968: Subtask scrape_teams_9-16
[2023-05-07T15:15:02.519+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T15:15:02.576+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T15:15:02.629+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_9-16
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T15:15:03.819+0000] {helpers.py:86} INFO - Detroit Pistons: Successfully scraped!
[2023-05-07T15:15:05.513+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T15:15:05.521+0000] {helpers.py:86} INFO - Golden State Warriors: Successfully scraped!
[2023-05-07T15:15:06.676+0000] {helpers.py:86} INFO - Houston Rockets: Successfully scraped!
[2023-05-07T15:15:08.542+0000] {helpers.py:86} INFO - Indiana Pacers: Successfully scraped!
[2023-05-07T15:15:09.284+0000] {helpers.py:86} INFO - Los Angeles Clippers: Successfully scraped!
[2023-05-07T15:15:10.247+0000] {helpers.py:86} INFO - Los Angeles Lakers: Successfully scraped!
[2023-05-07T15:15:11.226+0000] {helpers.py:86} INFO - Memphis Grizzlies: Successfully scraped!
[2023-05-07T15:15:11.954+0000] {helpers.py:86} INFO - Miami Heat: Successfully scraped!
[2023-05-07T15:15:11.959+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_9-16.csv
[2023-05-07T15:15:11.960+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-05-07T15:15:11.970+0000] {taskinstance.py:1332} INFO - Marking task as SUCCESS. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_9-16, execution_date=20220501T000000, start_date=20230507T151502, end_date=20230507T151511
[2023-05-07T15:15:12.007+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-05-07T15:15:12.026+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T15:18:52.448+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:18:52.470+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:18:52.471+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:18:52.472+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T15:18:52.500+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:18:52.542+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_9-16> on 2022-05-01 00:00:00+00:00
[2023-05-07T15:18:52.552+0000] {standard_task_runner.py:55} INFO - Started process 3278 to run task
[2023-05-07T15:18:52.564+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_9-16', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2978', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp7bs4it_c']
[2023-05-07T15:18:52.569+0000] {standard_task_runner.py:83} INFO - Job 2978: Subtask scrape_teams_9-16
[2023-05-07T15:18:52.726+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T15:18:52.796+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T15:18:52.841+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_9-16
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T15:18:53.444+0000] {helpers.py:86} INFO - Detroit Pistons: Successfully scraped!
[2023-05-07T15:18:54.144+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T15:18:54.151+0000] {helpers.py:86} INFO - Golden State Warriors: Successfully scraped!
[2023-05-07T15:18:54.791+0000] {helpers.py:86} INFO - Houston Rockets: Successfully scraped!
[2023-05-07T15:18:55.202+0000] {helpers.py:86} INFO - Indiana Pacers: Successfully scraped!
[2023-05-07T15:18:55.694+0000] {helpers.py:86} INFO - Los Angeles Clippers: Successfully scraped!
[2023-05-07T15:18:56.093+0000] {helpers.py:86} INFO - Los Angeles Lakers: Successfully scraped!
[2023-05-07T15:18:56.724+0000] {helpers.py:86} INFO - Memphis Grizzlies: Successfully scraped!
[2023-05-07T15:18:57.355+0000] {helpers.py:86} INFO - Miami Heat: Successfully scraped!
[2023-05-07T15:18:57.359+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_9-16.csv
[2023-05-07T15:18:57.361+0000] {python.py:177} INFO - Done. Returned value was:             scrape_timestamp  ...                                           selftext
0  2022-05-01T00:00:00+00:00  ...  ##[**FAQ**](https://www.reddit.com/r/warriors/...
0  2022-05-01T00:00:00+00:00  ...  Feels like Ja needs to put up huge numbers in ...
0  2022-05-01T00:00:00+00:00  ...                                                   
0  2022-05-01T00:00:00+00:00  ...                                          [removed]
0  2022-05-01T00:00:00+00:00  ...                                                   

[5 rows x 8 columns]
[2023-05-07T15:18:57.378+0000] {xcom.py:635} ERROR - Object of type DataFrame is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2023-05-07T15:18:57.380+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2305, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 240, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 627, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.7/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 176, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 170, in default
    return super().default(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2023-05-07T15:18:57.390+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_9-16, execution_date=20220501T000000, start_date=20230507T151852, end_date=20230507T151857
[2023-05-07T15:18:57.400+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2978 for task scrape_teams_9-16 (Object of type DataFrame is not JSON serializable; 3278)
[2023-05-07T15:18:57.441+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-07T15:18:57.497+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T15:26:02.975+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:26:03.012+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:26:03.014+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:26:03.022+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T15:26:03.024+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:26:03.118+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_9-16> on 2022-05-01 00:00:00+00:00
[2023-05-07T15:26:03.129+0000] {standard_task_runner.py:55} INFO - Started process 3468 to run task
[2023-05-07T15:26:03.141+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_9-16', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2986', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmpkhw73v6u']
[2023-05-07T15:26:03.152+0000] {standard_task_runner.py:83} INFO - Job 2986: Subtask scrape_teams_9-16
[2023-05-07T15:26:03.380+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T15:26:03.483+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T15:26:03.562+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_9-16
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T15:26:04.822+0000] {helpers.py:87} INFO - Detroit Pistons: Successfully scraped!
[2023-05-07T15:26:05.988+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T15:26:06.010+0000] {logging_mixin.py:137} INFO -             scrape_timestamp  ...                                           selftext
0  2022-05-01T00:00:00+00:00  ...  ##[**FAQ**](https://www.reddit.com/r/warriors/...

[1 rows x 8 columns]
[2023-05-07T15:26:06.011+0000] {helpers.py:87} INFO - Golden State Warriors: Successfully scraped!
[2023-05-07T15:26:06.610+0000] {helpers.py:87} INFO - Houston Rockets: Successfully scraped!
[2023-05-07T15:26:07.335+0000] {helpers.py:87} INFO - Indiana Pacers: Successfully scraped!
[2023-05-07T15:26:08.499+0000] {helpers.py:87} INFO - Los Angeles Clippers: Successfully scraped!
[2023-05-07T15:26:09.199+0000] {helpers.py:87} INFO - Los Angeles Lakers: Successfully scraped!
[2023-05-07T15:26:10.221+0000] {logging_mixin.py:137} INFO -             scrape_timestamp  ...                                           selftext
0  2022-05-01T00:00:00+00:00  ...  Feels like Ja needs to put up huge numbers in ...

[1 rows x 8 columns]
[2023-05-07T15:26:10.249+0000] {helpers.py:87} INFO - Memphis Grizzlies: Successfully scraped!
[2023-05-07T15:26:12.194+0000] {logging_mixin.py:137} INFO -             scrape_timestamp  ... selftext
0  2022-05-01T00:00:00+00:00  ...         

[1 rows x 8 columns]
[2023-05-07T15:26:12.240+0000] {helpers.py:87} INFO - Miami Heat: Successfully scraped!
[2023-05-07T15:26:12.248+0000] {helpers.py:103} INFO - Saved in /opt/***/data/output_scrape_teams_9-16.csv
[2023-05-07T15:26:12.251+0000] {python.py:177} INFO - Done. Returned value was:             scrape_timestamp  ...                                           selftext
0  2022-05-01T00:00:00+00:00  ...  ##[**FAQ**](https://www.reddit.com/r/warriors/...
0  2022-05-01T00:00:00+00:00  ...  Feels like Ja needs to put up huge numbers in ...
0  2022-05-01T00:00:00+00:00  ...                                                   

[3 rows x 8 columns]
[2023-05-07T15:26:12.274+0000] {xcom.py:635} ERROR - Object of type DataFrame is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2023-05-07T15:26:12.276+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2305, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 240, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 627, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.7/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 176, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 170, in default
    return super().default(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2023-05-07T15:26:12.287+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_9-16, execution_date=20220501T000000, start_date=20230507T152602, end_date=20230507T152612
[2023-05-07T15:26:12.307+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2986 for task scrape_teams_9-16 (Object of type DataFrame is not JSON serializable; 3468)
[2023-05-07T15:26:12.361+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-07T15:26:12.399+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-08T23:45:53.767+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:45:53.776+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:45:53.777+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:45:53.779+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-08T23:45:53.782+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:45:53.800+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_9-16> on 2022-05-01 00:00:00+00:00
[2023-05-08T23:45:53.807+0000] {standard_task_runner.py:55} INFO - Started process 224 to run task
[2023-05-08T23:45:53.816+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_9-16', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '3102', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmpq6o9rb9_']
[2023-05-08T23:45:53.820+0000] {standard_task_runner.py:83} INFO - Job 3102: Subtask scrape_teams_9-16
[2023-05-08T23:45:53.939+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [running]> on host f41dbfa3d325
[2023-05-08T23:45:53.986+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-08T23:45:54.035+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_9-16
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-08T23:45:54.041+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/helpers.py", line 59, in scrape_and_save
    after = datetime.fromisoformat(f"{{ execution_date }}")
ValueError: Invalid isoformat string: '{ execution_date }'
[2023-05-08T23:45:54.058+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_9-16, execution_date=20220501T000000, start_date=20230508T234553, end_date=20230508T234554
[2023-05-08T23:45:54.069+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 3102 for task scrape_teams_9-16 (Invalid isoformat string: '{ execution_date }'; 224)
[2023-05-08T23:45:54.106+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-08T23:45:54.131+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-08T23:48:25.177+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:48:25.191+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:48:25.192+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:48:25.193+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-08T23:48:25.194+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:48:25.208+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_9-16> on 2022-05-01 00:00:00+00:00
[2023-05-08T23:48:25.215+0000] {standard_task_runner.py:55} INFO - Started process 694 to run task
[2023-05-08T23:48:25.219+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_9-16', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '3244', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmpkgq2u8df']
[2023-05-08T23:48:25.223+0000] {standard_task_runner.py:83} INFO - Job 3244: Subtask scrape_teams_9-16
[2023-05-08T23:48:25.333+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [running]> on host f41dbfa3d325
[2023-05-08T23:48:25.396+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-08T23:48:25.469+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_9-16
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-08T23:48:25.473+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/helpers.py", line 59, in scrape_and_save
    after = datetime.fromisoformat("{{ execution_date }}")
ValueError: Invalid isoformat string: '{{ execution_date }}'
[2023-05-08T23:48:25.487+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_9-16, execution_date=20220501T000000, start_date=20230508T234825, end_date=20230508T234825
[2023-05-08T23:48:25.508+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 3244 for task scrape_teams_9-16 (Invalid isoformat string: '{{ execution_date }}'; 694)
[2023-05-08T23:48:25.555+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-08T23:48:25.613+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-08T23:51:50.332+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:51:50.347+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:51:50.348+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:51:50.349+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-08T23:51:50.350+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:51:50.373+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_9-16> on 2022-05-01 00:00:00+00:00
[2023-05-08T23:51:50.379+0000] {standard_task_runner.py:55} INFO - Started process 897 to run task
[2023-05-08T23:51:50.388+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_9-16', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '3282', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmpmwkrd267']
[2023-05-08T23:51:50.398+0000] {standard_task_runner.py:83} INFO - Job 3282: Subtask scrape_teams_9-16
[2023-05-08T23:51:50.540+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_9-16 scheduled__2022-05-01T00:00:00+00:00 [running]> on host f41dbfa3d325
[2023-05-08T23:51:50.590+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-08T23:51:50.645+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_9-16
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-08T23:52:06.643+0000] {helpers.py:94} INFO - Detroit Pistons: Successfully scraped!
[2023-05-08T23:52:23.467+0000] {helpers.py:94} INFO - Golden State Warriors: Successfully scraped!
[2023-05-08T23:52:39.775+0000] {helpers.py:94} INFO - Houston Rockets: Successfully scraped!
[2023-05-08T23:52:55.567+0000] {helpers.py:94} INFO - Indiana Pacers: Successfully scraped!
[2023-05-08T23:53:11.319+0000] {helpers.py:94} INFO - Los Angeles Clippers: Successfully scraped!
[2023-05-08T23:53:27.020+0000] {helpers.py:94} INFO - Los Angeles Lakers: Successfully scraped!
[2023-05-08T23:53:42.221+0000] {helpers.py:94} INFO - Memphis Grizzlies: Successfully scraped!
[2023-05-08T23:53:54.381+0000] {helpers.py:94} INFO - Miami Heat: Successfully scraped!
[2023-05-08T23:53:54.395+0000] {helpers.py:110} INFO - Saved in /opt/***/data/output_scrape_teams_9-16.csv
[2023-05-08T23:53:54.396+0000] {python.py:177} INFO - Done. Returned value was:      created_timestamp  ...                                           selftext
0  2023-05-08 21:56:11  ...  reminder to only buy Peton merch from pistons ...
0  2023-05-08 18:35:45  ...  Its always nice to see our players in Teal, a...
0  2023-05-08 18:08:21  ...             It was Andre Drummond and Kyle Singler
0  2023-05-08 18:07:50  ...                            Good shit too our boys.
0  2023-05-08 17:53:15  ...                                                   
..                 ...  ...                                                ...
0  2023-05-04 19:19:55  ...                                                   
0  2023-05-04 17:55:10  ...                   Id say Id be a 8.5.\n\nDiscuss
0  2023-05-04 17:32:34  ...  This is talked about a lot in Twitter since bu...
0  2023-05-04 15:58:56  ...                                                   
0  2023-05-04 15:42:13  ...                                                   

[1996 rows x 7 columns]
[2023-05-08T23:53:54.424+0000] {xcom.py:635} ERROR - Object of type DataFrame is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2023-05-08T23:53:54.429+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2305, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 240, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 627, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.7/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 176, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 170, in default
    return super().default(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2023-05-08T23:53:54.440+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_9-16, execution_date=20220501T000000, start_date=20230508T235150, end_date=20230508T235354
[2023-05-08T23:53:54.449+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 3282 for task scrape_teams_9-16 (Object of type DataFrame is not JSON serializable; 897)
[2023-05-08T23:53:54.536+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-08T23:53:54.567+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
