[2023-05-07T03:19:19.414+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:19:19.465+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:19:19.467+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:19:19.470+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T03:19:19.471+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:19:19.577+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_1-8> on 2022-05-01 00:00:00+00:00
[2023-05-07T03:19:19.695+0000] {standard_task_runner.py:55} INFO - Started process 1048 to run task
[2023-05-07T03:19:19.746+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_1-8', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2651', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp05vxjd0s']
[2023-05-07T03:19:19.765+0000] {standard_task_runner.py:83} INFO - Job 2651: Subtask scrape_teams_1-8
[2023-05-07T03:19:20.357+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T03:19:20.918+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_1-8
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T03:19:20.936+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
TypeError: scrape_and_save() missing 1 required positional argument: 'current_date'
[2023-05-07T03:19:21.005+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_1-8, execution_date=20220501T000000, start_date=20230507T031919, end_date=20230507T031921
[2023-05-07T03:19:21.042+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2651 for task scrape_teams_1-8 (scrape_and_save() missing 1 required positional argument: 'current_date'; 1048)
[2023-05-07T03:19:21.178+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-07T03:19:21.380+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T03:21:42.993+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:21:43.237+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:21:43.252+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:21:43.257+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T03:21:43.263+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:21:43.375+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_1-8> on 2022-05-01 00:00:00+00:00
[2023-05-07T03:21:43.419+0000] {standard_task_runner.py:55} INFO - Started process 1436 to run task
[2023-05-07T03:21:43.442+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_1-8', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2760', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmpgamsatfi']
[2023-05-07T03:21:43.487+0000] {standard_task_runner.py:83} INFO - Job 2760: Subtask scrape_teams_1-8
[2023-05-07T03:21:43.987+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T03:21:44.284+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T03:21:44.573+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_1-8
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T03:21:46.344+0000] {helpers.py:86} INFO - Atlanta Hawks: Successfully scraped!
[2023-05-07T03:21:47.021+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T03:21:47.144+0000] {helpers.py:86} INFO - Boston Celtics: Successfully scraped!
[2023-05-07T03:21:48.183+0000] {helpers.py:86} INFO - Brooklyn Nets: Successfully scraped!
[2023-05-07T03:21:48.406+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:48.410+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:48.411+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:21:49.779+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:49.780+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:49.782+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:21:50.984+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:50.985+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:50.986+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:21:52.158+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:52.159+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:52.166+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:21:53.319+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:53.320+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:53.321+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:21:54.474+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:54.476+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:54.477+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:21:55.658+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:55.658+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:55.659+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:21:56.800+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:56.803+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:56.805+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:21:57.985+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:57.986+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:57.988+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:21:59.137+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:59.142+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:59.150+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:00.320+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:00.321+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:00.323+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:01.474+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:01.475+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:01.476+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:22:02.625+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:02.627+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:02.627+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:22:03.962+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:03.973+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:03.995+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:22:05.180+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:05.184+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:05.188+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:22:06.333+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:06.335+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:06.336+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:22:07.484+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:07.486+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:07.487+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:22:08.942+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:08.943+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:08.944+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:22:10.128+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:10.130+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:10.131+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:22:11.284+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:11.286+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:11.287+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:22:12.441+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:12.442+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:12.443+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:13.598+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:13.600+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:13.601+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:14.768+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:14.769+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:14.771+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:22:15.934+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:15.935+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:15.936+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:22:17.272+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:17.273+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:17.274+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:22:18.755+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:18.757+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:18.760+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:22:20.127+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:20.129+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:20.131+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:22:21.285+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:21.287+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:21.288+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:22:22.435+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:22.437+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:22.437+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:22:23.583+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:23.584+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:23.585+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:22:24.733+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:24.735+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:24.735+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:22:25.881+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:25.891+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:25.892+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:27.040+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:27.041+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:27.045+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:28.403+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:28.404+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:28.405+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:22:29.576+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:29.587+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:29.590+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:22:30.762+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:30.763+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:30.764+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:22:32.068+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:32.074+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:32.075+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:22:33.243+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:33.245+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:33.247+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:22:34.436+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:34.439+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:34.440+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:22:35.594+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:35.595+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:35.596+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:22:36.749+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:36.751+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:36.752+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:22:38.071+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:38.073+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:38.076+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:22:39.226+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:39.227+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:39.228+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:40.389+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:40.390+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:40.391+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:41.544+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:41.546+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:41.547+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:22:42.708+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:42.709+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:42.710+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:22:44.058+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:44.061+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:44.063+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:22:45.388+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:45.391+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:45.392+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:22:46.593+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:46.611+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:46.616+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:22:47.773+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:47.783+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:47.820+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:22:48.992+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:48.998+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:49.001+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:22:50.156+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:50.161+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:50.185+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:22:51.364+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:51.366+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:51.367+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:22:52.514+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:52.516+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:52.516+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:53.671+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:53.685+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:53.686+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:54.722+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_1-8.csv
[2023-05-07T03:22:54.726+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-05-07T03:22:54.761+0000] {taskinstance.py:1332} INFO - Marking task as SUCCESS. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_1-8, execution_date=20220501T000000, start_date=20230507T032143, end_date=20230507T032254
[2023-05-07T03:22:54.862+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-05-07T03:22:54.945+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T03:38:06.016+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:38:06.026+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:38:06.027+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:38:06.028+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T03:38:06.029+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:38:06.044+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_1-8> on 2022-05-01 00:00:00+00:00
[2023-05-07T03:38:06.053+0000] {standard_task_runner.py:55} INFO - Started process 240 to run task
[2023-05-07T03:38:06.059+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_1-8', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2829', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmpi6v_32n6']
[2023-05-07T03:38:06.063+0000] {standard_task_runner.py:83} INFO - Job 2829: Subtask scrape_teams_1-8
[2023-05-07T03:38:06.196+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T03:38:06.246+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T03:38:06.301+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_1-8
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T03:38:07.224+0000] {helpers.py:86} INFO - Atlanta Hawks: Successfully scraped!
[2023-05-07T03:38:08.141+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T03:38:08.149+0000] {helpers.py:86} INFO - Boston Celtics: Successfully scraped!
[2023-05-07T03:38:08.668+0000] {helpers.py:86} INFO - Brooklyn Nets: Successfully scraped!
[2023-05-07T03:38:09.213+0000] {helpers.py:86} INFO - Charlotte Hornets: Successfully scraped!
[2023-05-07T03:38:09.721+0000] {helpers.py:86} INFO - Chicago Bulls: Successfully scraped!
[2023-05-07T03:38:10.913+0000] {helpers.py:86} INFO - Cleveland Cavaliers: Successfully scraped!
[2023-05-07T03:38:12.728+0000] {helpers.py:86} INFO - Dallas Mavericks: Successfully scraped!
[2023-05-07T03:38:13.677+0000] {helpers.py:86} INFO - Denver Nuggets: Successfully scraped!
[2023-05-07T03:38:13.692+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_1-8.csv
[2023-05-07T03:38:13.696+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-05-07T03:38:13.719+0000] {taskinstance.py:1332} INFO - Marking task as SUCCESS. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_1-8, execution_date=20220501T000000, start_date=20230507T033806, end_date=20230507T033813
[2023-05-07T03:38:13.754+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-05-07T03:38:13.788+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T05:14:58.764+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T05:14:58.782+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T05:14:58.784+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T05:14:58.786+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T05:14:58.787+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T05:14:58.803+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_1-8> on 2022-05-01 00:00:00+00:00
[2023-05-07T05:14:58.812+0000] {standard_task_runner.py:55} INFO - Started process 2185 to run task
[2023-05-07T05:14:58.828+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_1-8', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2889', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp4u6xhzwk']
[2023-05-07T05:14:58.866+0000] {standard_task_runner.py:83} INFO - Job 2889: Subtask scrape_teams_1-8
[2023-05-07T05:14:59.050+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T05:14:59.146+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T05:14:59.261+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_1-8
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T05:14:59.822+0000] {helpers.py:86} INFO - Atlanta Hawks: Successfully scraped!
[2023-05-07T05:15:00.418+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T05:15:00.426+0000] {helpers.py:86} INFO - Boston Celtics: Successfully scraped!
[2023-05-07T05:15:00.857+0000] {helpers.py:86} INFO - Brooklyn Nets: Successfully scraped!
[2023-05-07T05:15:01.516+0000] {helpers.py:86} INFO - Charlotte Hornets: Successfully scraped!
[2023-05-07T05:15:02.071+0000] {helpers.py:86} INFO - Chicago Bulls: Successfully scraped!
[2023-05-07T05:15:03.523+0000] {helpers.py:86} INFO - Cleveland Cavaliers: Successfully scraped!
[2023-05-07T05:15:04.445+0000] {helpers.py:86} INFO - Dallas Mavericks: Successfully scraped!
[2023-05-07T05:15:05.127+0000] {helpers.py:86} INFO - Denver Nuggets: Successfully scraped!
[2023-05-07T05:15:05.162+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_1-8.csv
[2023-05-07T05:15:05.164+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-05-07T05:15:05.175+0000] {taskinstance.py:1332} INFO - Marking task as SUCCESS. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_1-8, execution_date=20220501T000000, start_date=20230507T051458, end_date=20230507T051505
[2023-05-07T05:15:05.216+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-05-07T05:15:05.247+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T15:15:02.335+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:15:02.349+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:15:02.351+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:15:02.355+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T15:15:02.357+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:15:02.380+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_1-8> on 2022-05-01 00:00:00+00:00
[2023-05-07T15:15:02.386+0000] {standard_task_runner.py:55} INFO - Started process 3130 to run task
[2023-05-07T15:15:02.399+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_1-8', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2969', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmpfzub9wod']
[2023-05-07T15:15:02.411+0000] {standard_task_runner.py:83} INFO - Job 2969: Subtask scrape_teams_1-8
[2023-05-07T15:15:02.552+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T15:15:02.601+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T15:15:02.657+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_1-8
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T15:15:03.656+0000] {helpers.py:86} INFO - Atlanta Hawks: Successfully scraped!
[2023-05-07T15:15:05.339+0000] {helpers.py:86} INFO - Boston Celtics: Successfully scraped!
[2023-05-07T15:15:06.911+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T15:15:06.920+0000] {helpers.py:86} INFO - Brooklyn Nets: Successfully scraped!
[2023-05-07T15:15:08.540+0000] {helpers.py:86} INFO - Charlotte Hornets: Successfully scraped!
[2023-05-07T15:15:09.353+0000] {helpers.py:86} INFO - Chicago Bulls: Successfully scraped!
[2023-05-07T15:15:10.104+0000] {helpers.py:86} INFO - Cleveland Cavaliers: Successfully scraped!
[2023-05-07T15:15:11.141+0000] {helpers.py:86} INFO - Dallas Mavericks: Successfully scraped!
[2023-05-07T15:15:11.848+0000] {helpers.py:86} INFO - Denver Nuggets: Successfully scraped!
[2023-05-07T15:15:11.853+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_1-8.csv
[2023-05-07T15:15:11.854+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-05-07T15:15:11.864+0000] {taskinstance.py:1332} INFO - Marking task as SUCCESS. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_1-8, execution_date=20220501T000000, start_date=20230507T151502, end_date=20230507T151511
[2023-05-07T15:15:11.898+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-05-07T15:15:11.925+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T15:18:52.351+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:18:52.362+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:18:52.366+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:18:52.367+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T15:18:52.369+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:18:52.391+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_1-8> on 2022-05-01 00:00:00+00:00
[2023-05-07T15:18:52.399+0000] {standard_task_runner.py:55} INFO - Started process 3275 to run task
[2023-05-07T15:18:52.407+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_1-8', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2975', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmprp90j6zv']
[2023-05-07T15:18:52.411+0000] {standard_task_runner.py:83} INFO - Job 2975: Subtask scrape_teams_1-8
[2023-05-07T15:18:52.625+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T15:18:52.679+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T15:18:52.758+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_1-8
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T15:18:53.133+0000] {helpers.py:86} INFO - Atlanta Hawks: Successfully scraped!
[2023-05-07T15:18:53.890+0000] {helpers.py:86} INFO - Boston Celtics: Successfully scraped!
[2023-05-07T15:18:54.474+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T15:18:54.485+0000] {helpers.py:86} INFO - Brooklyn Nets: Successfully scraped!
[2023-05-07T15:18:54.977+0000] {helpers.py:86} INFO - Charlotte Hornets: Successfully scraped!
[2023-05-07T15:18:55.654+0000] {helpers.py:86} INFO - Chicago Bulls: Successfully scraped!
[2023-05-07T15:18:56.005+0000] {helpers.py:86} INFO - Cleveland Cavaliers: Successfully scraped!
[2023-05-07T15:18:57.066+0000] {helpers.py:86} INFO - Dallas Mavericks: Successfully scraped!
[2023-05-07T15:18:57.437+0000] {helpers.py:86} INFO - Denver Nuggets: Successfully scraped!
[2023-05-07T15:18:57.442+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_1-8.csv
[2023-05-07T15:18:57.478+0000] {python.py:177} INFO - Done. Returned value was:             scrape_timestamp  ...                                           selftext
0  2022-05-01T00:00:00+00:00  ...  Good morning/afternoon/evening, \n\nThis is a ...
0  2022-05-01T00:00:00+00:00  ...                                                   
0  2022-05-01T00:00:00+00:00  ...                                                   

[3 rows x 8 columns]
[2023-05-07T15:18:57.497+0000] {xcom.py:635} ERROR - Object of type DataFrame is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2023-05-07T15:18:57.499+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2305, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 240, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 627, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.7/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 176, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 170, in default
    return super().default(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2023-05-07T15:18:57.510+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_1-8, execution_date=20220501T000000, start_date=20230507T151852, end_date=20230507T151857
[2023-05-07T15:18:57.523+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2975 for task scrape_teams_1-8 (Object of type DataFrame is not JSON serializable; 3275)
[2023-05-07T15:18:57.557+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-07T15:18:57.574+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T15:26:02.666+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:26:02.712+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:26:02.761+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:26:02.770+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T15:26:02.772+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:26:02.809+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_1-8> on 2022-05-01 00:00:00+00:00
[2023-05-07T15:26:02.825+0000] {standard_task_runner.py:55} INFO - Started process 3466 to run task
[2023-05-07T15:26:02.866+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_1-8', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2984', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp47rzzaxu']
[2023-05-07T15:26:02.876+0000] {standard_task_runner.py:83} INFO - Job 2984: Subtask scrape_teams_1-8
[2023-05-07T15:26:03.127+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T15:26:03.215+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T15:26:03.419+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_1-8
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T15:26:04.858+0000] {helpers.py:87} INFO - Atlanta Hawks: Successfully scraped!
[2023-05-07T15:26:05.757+0000] {helpers.py:87} INFO - Boston Celtics: Successfully scraped!
[2023-05-07T15:26:06.750+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T15:26:06.766+0000] {logging_mixin.py:137} INFO -             scrape_timestamp  ...                                           selftext
0  2022-05-01T00:00:00+00:00  ...  Good morning/afternoon/evening, \n\nThis is a ...

[1 rows x 8 columns]
[2023-05-07T15:26:06.768+0000] {helpers.py:87} INFO - Brooklyn Nets: Successfully scraped!
[2023-05-07T15:26:07.447+0000] {helpers.py:87} INFO - Charlotte Hornets: Successfully scraped!
[2023-05-07T15:26:08.491+0000] {logging_mixin.py:137} INFO -             scrape_timestamp  ... selftext
0  2022-05-01T00:00:00+00:00  ...         

[1 rows x 8 columns]
[2023-05-07T15:26:08.493+0000] {helpers.py:87} INFO - Chicago Bulls: Successfully scraped!
[2023-05-07T15:26:08.934+0000] {helpers.py:87} INFO - Cleveland Cavaliers: Successfully scraped!
[2023-05-07T15:26:09.422+0000] {logging_mixin.py:137} INFO -             scrape_timestamp  ... selftext
0  2022-05-01T00:00:00+00:00  ...         

[1 rows x 8 columns]
[2023-05-07T15:26:09.423+0000] {helpers.py:87} INFO - Dallas Mavericks: Successfully scraped!
[2023-05-07T15:26:10.403+0000] {helpers.py:87} INFO - Denver Nuggets: Successfully scraped!
[2023-05-07T15:26:10.417+0000] {helpers.py:103} INFO - Saved in /opt/***/data/output_scrape_teams_1-8.csv
[2023-05-07T15:26:10.424+0000] {python.py:177} INFO - Done. Returned value was:             scrape_timestamp  ...                                           selftext
0  2022-05-01T00:00:00+00:00  ...  Good morning/afternoon/evening, \n\nThis is a ...
0  2022-05-01T00:00:00+00:00  ...                                                   
0  2022-05-01T00:00:00+00:00  ...                                                   

[3 rows x 8 columns]
[2023-05-07T15:26:10.462+0000] {xcom.py:635} ERROR - Object of type DataFrame is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2023-05-07T15:26:10.475+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2305, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 240, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 627, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.7/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 176, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 170, in default
    return super().default(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2023-05-07T15:26:10.490+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_1-8, execution_date=20220501T000000, start_date=20230507T152602, end_date=20230507T152610
[2023-05-07T15:26:10.503+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2984 for task scrape_teams_1-8 (Object of type DataFrame is not JSON serializable; 3466)
[2023-05-07T15:26:10.548+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-07T15:26:10.586+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-08T23:45:53.742+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:45:53.759+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:45:53.760+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:45:53.762+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-08T23:45:53.764+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:45:53.781+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_1-8> on 2022-05-01 00:00:00+00:00
[2023-05-08T23:45:53.788+0000] {standard_task_runner.py:55} INFO - Started process 223 to run task
[2023-05-08T23:45:53.803+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_1-8', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '3101', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp3vadmrdm']
[2023-05-08T23:45:53.809+0000] {standard_task_runner.py:83} INFO - Job 3101: Subtask scrape_teams_1-8
[2023-05-08T23:45:53.955+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [running]> on host f41dbfa3d325
[2023-05-08T23:45:54.000+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-08T23:45:54.057+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_1-8
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-08T23:45:54.062+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/helpers.py", line 59, in scrape_and_save
    after = datetime.fromisoformat(f"{{ execution_date }}")
ValueError: Invalid isoformat string: '{ execution_date }'
[2023-05-08T23:45:54.076+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_1-8, execution_date=20220501T000000, start_date=20230508T234553, end_date=20230508T234554
[2023-05-08T23:45:54.086+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 3101 for task scrape_teams_1-8 (Invalid isoformat string: '{ execution_date }'; 223)
[2023-05-08T23:45:54.137+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-08T23:45:54.178+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-08T23:48:25.148+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:48:25.159+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:48:25.162+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:48:25.163+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-08T23:48:25.164+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:48:25.182+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_1-8> on 2022-05-01 00:00:00+00:00
[2023-05-08T23:48:25.188+0000] {standard_task_runner.py:55} INFO - Started process 691 to run task
[2023-05-08T23:48:25.194+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_1-8', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '3241', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmphig8igjn']
[2023-05-08T23:48:25.204+0000] {standard_task_runner.py:83} INFO - Job 3241: Subtask scrape_teams_1-8
[2023-05-08T23:48:25.299+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [running]> on host f41dbfa3d325
[2023-05-08T23:48:25.371+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-08T23:48:25.453+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_1-8
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-08T23:48:25.465+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/helpers.py", line 59, in scrape_and_save
    after = datetime.fromisoformat("{{ execution_date }}")
ValueError: Invalid isoformat string: '{{ execution_date }}'
[2023-05-08T23:48:25.482+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_1-8, execution_date=20220501T000000, start_date=20230508T234825, end_date=20230508T234825
[2023-05-08T23:48:25.497+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 3241 for task scrape_teams_1-8 (Invalid isoformat string: '{{ execution_date }}'; 691)
[2023-05-08T23:48:25.537+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-08T23:48:25.563+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-08T23:51:50.284+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:51:50.299+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:51:50.301+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:51:50.306+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-08T23:51:50.307+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:51:50.325+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_1-8> on 2022-05-01 00:00:00+00:00
[2023-05-08T23:51:50.332+0000] {standard_task_runner.py:55} INFO - Started process 896 to run task
[2023-05-08T23:51:50.345+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_1-8', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '3281', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp34irgvv5']
[2023-05-08T23:51:50.348+0000] {standard_task_runner.py:83} INFO - Job 3281: Subtask scrape_teams_1-8
[2023-05-08T23:51:50.463+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_1-8 scheduled__2022-05-01T00:00:00+00:00 [running]> on host f41dbfa3d325
[2023-05-08T23:51:50.529+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-08T23:51:50.599+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_1-8
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-08T23:52:04.883+0000] {helpers.py:94} INFO - Atlanta Hawks: Successfully scraped!
[2023-05-08T23:52:21.909+0000] {helpers.py:94} INFO - Boston Celtics: Successfully scraped!
[2023-05-08T23:52:37.578+0000] {helpers.py:94} INFO - Brooklyn Nets: Successfully scraped!
[2023-05-08T23:52:54.610+0000] {helpers.py:94} INFO - Charlotte Hornets: Successfully scraped!
[2023-05-08T23:53:09.409+0000] {helpers.py:94} INFO - Chicago Bulls: Successfully scraped!
[2023-05-08T23:53:24.758+0000] {helpers.py:94} INFO - Cleveland Cavaliers: Successfully scraped!
[2023-05-08T23:53:40.217+0000] {helpers.py:94} INFO - Dallas Mavericks: Successfully scraped!
[2023-05-08T23:53:52.883+0000] {helpers.py:94} INFO - Denver Nuggets: Successfully scraped!
[2023-05-08T23:53:52.900+0000] {helpers.py:110} INFO - Saved in /opt/***/data/output_scrape_teams_1-8.csv
[2023-05-08T23:53:52.902+0000] {python.py:177} INFO - Done. Returned value was:      created_timestamp  ...                                           selftext
0  2023-05-08 23:42:28  ...  https://youtu.be/cA8xm31l1DU\n\nIm not sure i...
0  2023-05-08 22:42:26  ...  What would be the best version of our young gu...
0  2023-05-08 22:36:59  ...                                                   
0  2023-05-08 22:34:44  ...                                                   
0  2023-05-08 20:07:10  ...                                                   
..                 ...  ...                                                ...
0  2023-05-02 23:43:12  ...  Im pumped about the competition that we have ...
0  2023-05-02 23:25:50  ...                                                   
0  2023-05-02 23:15:12  ...                                                   
0  2023-05-02 23:03:47  ...                                                   
0  2023-05-02 22:56:27  ...                                                   

[1994 rows x 7 columns]
[2023-05-08T23:53:52.920+0000] {xcom.py:635} ERROR - Object of type DataFrame is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2023-05-08T23:53:52.923+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2305, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 240, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 627, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.7/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 176, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 170, in default
    return super().default(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2023-05-08T23:53:52.934+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_1-8, execution_date=20220501T000000, start_date=20230508T235150, end_date=20230508T235352
[2023-05-08T23:53:52.946+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 3281 for task scrape_teams_1-8 (Object of type DataFrame is not JSON serializable; 896)
[2023-05-08T23:53:53.016+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-08T23:53:53.033+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
