[2023-05-07T03:19:20.430+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:19:20.516+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:19:20.521+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:19:20.542+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T03:19:20.549+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:19:20.655+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_25-30> on 2022-05-01 00:00:00+00:00
[2023-05-07T03:19:20.696+0000] {standard_task_runner.py:55} INFO - Started process 1058 to run task
[2023-05-07T03:19:20.735+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_25-30', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2656', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmps0t0cqi3']
[2023-05-07T03:19:20.751+0000] {standard_task_runner.py:83} INFO - Job 2656: Subtask scrape_teams_25-30
[2023-05-07T03:19:21.269+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T03:19:21.579+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_25-30
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T03:19:21.590+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
TypeError: scrape_and_save() missing 1 required positional argument: 'current_date'
[2023-05-07T03:19:21.628+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_25-30, execution_date=20220501T000000, start_date=20230507T031920, end_date=20230507T031921
[2023-05-07T03:19:21.667+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2656 for task scrape_teams_25-30 (scrape_and_save() missing 1 required positional argument: 'current_date'; 1058)
[2023-05-07T03:19:21.771+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-07T03:19:21.833+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T03:21:43.504+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:21:43.569+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:21:43.595+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:21:43.596+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T03:21:43.602+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:21:43.691+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_25-30> on 2022-05-01 00:00:00+00:00
[2023-05-07T03:21:43.746+0000] {standard_task_runner.py:55} INFO - Started process 1437 to run task
[2023-05-07T03:21:43.796+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_25-30', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2761', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmprocjjtpb']
[2023-05-07T03:21:43.848+0000] {standard_task_runner.py:83} INFO - Job 2761: Subtask scrape_teams_25-30
[2023-05-07T03:21:44.419+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T03:21:44.625+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T03:21:44.786+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_25-30
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T03:21:45.885+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T03:21:46.008+0000] {helpers.py:86} INFO - Portland Trail Blazers: Successfully scraped!
[2023-05-07T03:21:47.067+0000] {helpers.py:86} INFO - Sacramento Kings: Successfully scraped!
[2023-05-07T03:21:47.877+0000] {helpers.py:86} INFO - San Antonio Spurs: Successfully scraped!
[2023-05-07T03:21:48.223+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:48.225+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:48.226+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:21:49.565+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:49.567+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:49.569+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:21:50.919+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:50.920+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:50.922+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:21:52.081+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:52.083+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:52.084+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:21:53.230+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:53.231+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:53.232+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:21:54.569+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:54.570+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:54.571+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:21:55.730+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:55.732+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:55.733+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:21:57.055+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:57.057+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:57.059+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:21:58.211+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:58.212+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:58.213+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:21:59.364+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:59.365+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:21:59.367+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:00.518+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:00.519+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:00.520+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:01.857+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:01.858+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:01.859+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:22:03.197+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:03.198+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:03.200+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:22:04.349+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:04.351+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:04.353+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:22:05.499+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:05.500+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:05.501+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:22:06.644+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:06.652+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:06.654+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:22:07.816+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:07.818+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:07.819+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:22:08.986+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:08.988+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:08.988+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:22:10.350+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:10.351+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:10.353+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:22:11.503+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:11.504+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:11.504+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:22:12.650+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:12.651+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:12.660+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:13.807+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:13.809+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:13.810+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:15.182+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:15.185+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:15.191+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:22:16.348+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:16.349+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:16.350+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:22:17.514+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:17.515+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:17.516+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:22:18.756+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:18.758+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:18.767+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:22:20.103+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:20.106+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:20.107+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:22:21.256+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:21.257+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:21.258+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:22:22.402+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:22.405+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:22.406+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:22:23.564+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:23.566+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:23.567+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:22:24.725+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:24.728+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:24.729+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:22:25.876+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:25.878+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:25.879+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T03:22:27.039+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:27.042+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:22:27.045+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T03:22:28.078+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_25-30.csv
[2023-05-07T03:22:28.086+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-05-07T03:22:28.107+0000] {taskinstance.py:1332} INFO - Marking task as SUCCESS. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_25-30, execution_date=20220501T000000, start_date=20230507T032143, end_date=20230507T032228
[2023-05-07T03:22:28.161+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-05-07T03:22:28.206+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T03:38:14.667+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:38:14.680+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T03:38:14.681+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:38:14.682+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T03:38:14.683+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T03:38:14.691+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_25-30> on 2022-05-01 00:00:00+00:00
[2023-05-07T03:38:14.696+0000] {standard_task_runner.py:55} INFO - Started process 245 to run task
[2023-05-07T03:38:14.700+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_25-30', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2831', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmpkptue_hi']
[2023-05-07T03:38:14.702+0000] {standard_task_runner.py:83} INFO - Job 2831: Subtask scrape_teams_25-30
[2023-05-07T03:38:14.763+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T03:38:14.787+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T03:38:14.818+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_25-30
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T03:38:15.417+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T03:38:15.423+0000] {helpers.py:86} INFO - Portland Trail Blazers: Successfully scraped!
[2023-05-07T03:38:15.810+0000] {helpers.py:86} INFO - Sacramento Kings: Successfully scraped!
[2023-05-07T03:38:17.406+0000] {helpers.py:86} INFO - San Antonio Spurs: Successfully scraped!
[2023-05-07T03:38:18.869+0000] {helpers.py:86} INFO - Toronto Raptors: Successfully scraped!
[2023-05-07T03:38:19.219+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:19.220+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:19.222+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:38:20.538+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:20.539+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:20.540+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:38:21.997+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:22.034+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:22.036+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:38:23.381+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:23.383+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:23.384+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T03:38:24.535+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:24.536+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:24.537+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T03:38:25.900+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:25.938+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:25.940+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T03:38:27.088+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:27.090+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:27.092+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T03:38:28.237+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:28.240+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:28.242+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T03:38:29.402+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:29.439+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:29.440+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T03:38:30.846+0000] {helpers.py:86} INFO - Utah Jazz: Successfully scraped!
[2023-05-07T03:38:31.193+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:31.196+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:31.197+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T03:38:32.355+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:32.356+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:32.357+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T03:38:33.513+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:33.514+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T03:38:33.515+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T03:38:35.122+0000] {helpers.py:86} INFO - Washington Wizards: Successfully scraped!
[2023-05-07T03:38:35.127+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_25-30.csv
[2023-05-07T03:38:35.129+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-05-07T03:38:35.142+0000] {taskinstance.py:1332} INFO - Marking task as SUCCESS. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_25-30, execution_date=20220501T000000, start_date=20230507T033814, end_date=20230507T033835
[2023-05-07T03:38:35.194+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-05-07T03:38:35.217+0000] {taskinstance.py:2596} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-05-07T05:14:58.805+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T05:14:58.824+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T05:14:58.829+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T05:14:58.865+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T05:14:58.868+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T05:14:58.902+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_25-30> on 2022-05-01 00:00:00+00:00
[2023-05-07T05:14:58.910+0000] {standard_task_runner.py:55} INFO - Started process 2187 to run task
[2023-05-07T05:14:58.928+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_25-30', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2890', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp89qsn0oa']
[2023-05-07T05:14:58.939+0000] {standard_task_runner.py:83} INFO - Job 2890: Subtask scrape_teams_25-30
[2023-05-07T05:14:59.168+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T05:14:59.248+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T05:14:59.328+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_25-30
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T05:15:00.264+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:313: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(k, replacements))

[2023-05-07T05:15:00.272+0000] {helpers.py:86} INFO - Portland Trail Blazers: Successfully scraped!
[2023-05-07T05:15:01.460+0000] {helpers.py:86} INFO - Sacramento Kings: Successfully scraped!
[2023-05-07T05:15:07.504+0000] {helpers.py:86} INFO - San Antonio Spurs: Successfully scraped!
[2023-05-07T05:15:07.857+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:07.858+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:07.859+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T05:15:09.002+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:09.004+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:09.006+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T05:15:10.371+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:10.374+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:10.378+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T05:15:11.741+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:11.743+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:11.745+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T05:15:13.045+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:13.046+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:13.047+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T05:15:14.205+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:14.207+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:14.215+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T05:15:15.563+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:15.563+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:15.564+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T05:15:16.756+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:16.764+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:16.766+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T05:15:17.923+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:17.925+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:17.927+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T05:15:19.136+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:19.168+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:19.178+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T05:15:20.353+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:20.355+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:20.356+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T05:15:21.611+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:21.620+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:21.629+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T05:15:22.980+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:22.983+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:22.992+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T05:15:24.364+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:24.376+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:24.381+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T05:15:25.656+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:25.662+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:25.676+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T05:15:26.949+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:26.951+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:26.952+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T05:15:28.103+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:28.105+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:28.107+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T05:15:29.271+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:29.274+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:29.277+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T05:15:30.439+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:30.442+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:30.445+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T05:15:31.689+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:31.692+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:31.694+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T05:15:32.946+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:32.947+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:32.949+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T05:15:34.257+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:34.259+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:34.261+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T05:15:35.415+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:35.417+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:35.419+0000] {helpers.py:93} ERROR - Retrying! 9 attempts before skipping!
[2023-05-07T05:15:36.837+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:36.839+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:36.841+0000] {helpers.py:93} ERROR - Retrying! 8 attempts before skipping!
[2023-05-07T05:15:38.175+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:38.176+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:38.177+0000] {helpers.py:93} ERROR - Retrying! 7 attempts before skipping!
[2023-05-07T05:15:39.375+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:39.377+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:39.378+0000] {helpers.py:93} ERROR - Retrying! 6 attempts before skipping!
[2023-05-07T05:15:40.778+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:40.779+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:40.780+0000] {helpers.py:93} ERROR - Retrying! 5 attempts before skipping!
[2023-05-07T05:15:42.168+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:42.169+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:42.189+0000] {helpers.py:93} ERROR - Retrying! 4 attempts before skipping!
[2023-05-07T05:15:43.351+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:43.387+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:43.389+0000] {helpers.py:93} ERROR - Retrying! 3 attempts before skipping!
[2023-05-07T05:15:44.647+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:44.649+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:44.650+0000] {helpers.py:93} ERROR - Retrying! 2 attempts before skipping!
[2023-05-07T05:15:45.805+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:45.807+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:45.808+0000] {helpers.py:93} ERROR - Retrying! 1 attempts before skipping!
[2023-05-07T05:15:46.996+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:46.998+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:47.000+0000] {helpers.py:93} ERROR - Retrying! 0 attempts before skipping!
[2023-05-07T05:15:48.333+0000] {logging_mixin.py:137} INFO - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:48.334+0000] {helpers.py:92} ERROR - Expecting value: line 1 column 1 (char 0)
[2023-05-07T05:15:48.335+0000] {helpers.py:93} ERROR - Retrying! -1 attempts before skipping!
[2023-05-07T05:15:49.351+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_25-30.csv
[2023-05-07T05:15:49.377+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-05-07T05:15:49.405+0000] {taskinstance.py:1332} INFO - Marking task as SUCCESS. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_25-30, execution_date=20220501T000000, start_date=20230507T051458, end_date=20230507T051549
[2023-05-07T05:15:49.445+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-05-07T05:15:49.495+0000] {taskinstance.py:2596} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-05-07T15:15:02.261+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:15:02.286+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:15:02.288+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:15:02.289+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T15:15:02.290+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:15:02.309+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_25-30> on 2022-05-01 00:00:00+00:00
[2023-05-07T15:15:02.315+0000] {standard_task_runner.py:55} INFO - Started process 3127 to run task
[2023-05-07T15:15:02.320+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_25-30', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2967', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmps7nlp3yc']
[2023-05-07T15:15:02.331+0000] {standard_task_runner.py:83} INFO - Job 2967: Subtask scrape_teams_25-30
[2023-05-07T15:15:02.457+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T15:15:02.525+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T15:15:02.589+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_25-30
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T15:15:03.657+0000] {helpers.py:86} INFO - Portland Trail Blazers: Successfully scraped!
[2023-05-07T15:15:05.091+0000] {helpers.py:86} INFO - Sacramento Kings: Successfully scraped!
[2023-05-07T15:15:06.193+0000] {helpers.py:86} INFO - San Antonio Spurs: Successfully scraped!
[2023-05-07T15:15:07.672+0000] {helpers.py:86} INFO - Toronto Raptors: Successfully scraped!
[2023-05-07T15:15:09.384+0000] {helpers.py:86} INFO - Utah Jazz: Successfully scraped!
[2023-05-07T15:15:10.066+0000] {helpers.py:86} INFO - Washington Wizards: Successfully scraped!
[2023-05-07T15:15:10.098+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_25-30.csv
[2023-05-07T15:15:10.106+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-05-07T15:15:10.124+0000] {taskinstance.py:1332} INFO - Marking task as SUCCESS. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_25-30, execution_date=20220501T000000, start_date=20230507T151502, end_date=20230507T151510
[2023-05-07T15:15:10.180+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-05-07T15:15:10.203+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T15:18:52.448+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:18:52.465+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:18:52.467+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:18:52.468+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T15:18:52.469+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:18:52.520+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_25-30> on 2022-05-01 00:00:00+00:00
[2023-05-07T15:18:52.529+0000] {standard_task_runner.py:55} INFO - Started process 3277 to run task
[2023-05-07T15:18:52.540+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_25-30', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2977', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmpim5aqqyq']
[2023-05-07T15:18:52.543+0000] {standard_task_runner.py:83} INFO - Job 2977: Subtask scrape_teams_25-30
[2023-05-07T15:18:52.675+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T15:18:52.736+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T15:18:52.815+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_25-30
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T15:18:53.595+0000] {helpers.py:86} INFO - Portland Trail Blazers: Successfully scraped!
[2023-05-07T15:18:54.413+0000] {helpers.py:86} INFO - Sacramento Kings: Successfully scraped!
[2023-05-07T15:18:54.947+0000] {helpers.py:86} INFO - San Antonio Spurs: Successfully scraped!
[2023-05-07T15:18:55.296+0000] {helpers.py:86} INFO - Toronto Raptors: Successfully scraped!
[2023-05-07T15:18:55.844+0000] {helpers.py:86} INFO - Utah Jazz: Successfully scraped!
[2023-05-07T15:18:56.274+0000] {helpers.py:86} INFO - Washington Wizards: Successfully scraped!
[2023-05-07T15:18:56.280+0000] {helpers.py:102} INFO - Saved in /opt/***/data/output_scrape_teams_25-30.csv
[2023-05-07T15:18:56.282+0000] {python.py:177} INFO - Done. Returned value was: Empty DataFrame
Columns: []
Index: []
[2023-05-07T15:18:56.298+0000] {xcom.py:635} ERROR - Object of type DataFrame is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2023-05-07T15:18:56.300+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2305, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 240, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 627, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.7/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 176, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 170, in default
    return super().default(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2023-05-07T15:18:56.319+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_25-30, execution_date=20220501T000000, start_date=20230507T151852, end_date=20230507T151856
[2023-05-07T15:18:56.331+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2977 for task scrape_teams_25-30 (Object of type DataFrame is not JSON serializable; 3277)
[2023-05-07T15:18:56.377+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-07T15:18:56.401+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-07T15:26:02.838+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:26:02.882+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-07T15:26:02.885+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:26:02.887+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-07T15:26:02.888+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-07T15:26:02.941+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_25-30> on 2022-05-01 00:00:00+00:00
[2023-05-07T15:26:02.949+0000] {standard_task_runner.py:55} INFO - Started process 3467 to run task
[2023-05-07T15:26:02.995+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_25-30', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '2985', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp_yw7n2ir']
[2023-05-07T15:26:03.030+0000] {standard_task_runner.py:83} INFO - Job 2985: Subtask scrape_teams_25-30
[2023-05-07T15:26:03.319+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [running]> on host 6589836e9c08
[2023-05-07T15:26:03.429+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-07T15:26:03.532+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_25-30
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-07T15:26:04.868+0000] {helpers.py:87} INFO - Portland Trail Blazers: Successfully scraped!
[2023-05-07T15:26:05.829+0000] {helpers.py:87} INFO - Sacramento Kings: Successfully scraped!
[2023-05-07T15:26:06.554+0000] {helpers.py:87} INFO - San Antonio Spurs: Successfully scraped!
[2023-05-07T15:26:07.376+0000] {helpers.py:87} INFO - Toronto Raptors: Successfully scraped!
[2023-05-07T15:26:07.943+0000] {helpers.py:87} INFO - Utah Jazz: Successfully scraped!
[2023-05-07T15:26:08.628+0000] {helpers.py:87} INFO - Washington Wizards: Successfully scraped!
[2023-05-07T15:26:08.633+0000] {helpers.py:103} INFO - Saved in /opt/***/data/output_scrape_teams_25-30.csv
[2023-05-07T15:26:08.635+0000] {python.py:177} INFO - Done. Returned value was: Empty DataFrame
Columns: []
Index: []
[2023-05-07T15:26:08.648+0000] {xcom.py:635} ERROR - Object of type DataFrame is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2023-05-07T15:26:08.650+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2305, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 240, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 627, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.7/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 176, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 170, in default
    return super().default(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2023-05-07T15:26:08.663+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_25-30, execution_date=20220501T000000, start_date=20230507T152602, end_date=20230507T152608
[2023-05-07T15:26:08.673+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2985 for task scrape_teams_25-30 (Object of type DataFrame is not JSON serializable; 3467)
[2023-05-07T15:26:08.696+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-07T15:26:08.715+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-08T23:45:53.796+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:45:53.811+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:45:53.813+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:45:53.818+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-08T23:45:53.819+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:45:53.844+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_25-30> on 2022-05-01 00:00:00+00:00
[2023-05-08T23:45:53.851+0000] {standard_task_runner.py:55} INFO - Started process 226 to run task
[2023-05-08T23:45:53.860+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_25-30', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '3104', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp8q01wqox']
[2023-05-08T23:45:53.868+0000] {standard_task_runner.py:83} INFO - Job 3104: Subtask scrape_teams_25-30
[2023-05-08T23:45:53.980+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [running]> on host f41dbfa3d325
[2023-05-08T23:45:54.010+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-08T23:45:54.057+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_25-30
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-08T23:45:54.062+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/helpers.py", line 59, in scrape_and_save
    after = datetime.fromisoformat(f"{{ execution_date }}")
ValueError: Invalid isoformat string: '{ execution_date }'
[2023-05-08T23:45:54.082+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_25-30, execution_date=20220501T000000, start_date=20230508T234553, end_date=20230508T234554
[2023-05-08T23:45:54.092+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 3104 for task scrape_teams_25-30 (Invalid isoformat string: '{ execution_date }'; 226)
[2023-05-08T23:45:54.124+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-08T23:45:54.166+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-08T23:48:25.157+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:48:25.167+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:48:25.168+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:48:25.169+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-08T23:48:25.170+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:48:25.181+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_25-30> on 2022-05-01 00:00:00+00:00
[2023-05-08T23:48:25.190+0000] {standard_task_runner.py:55} INFO - Started process 692 to run task
[2023-05-08T23:48:25.196+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_25-30', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '3242', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmp42bc7yzg']
[2023-05-08T23:48:25.200+0000] {standard_task_runner.py:83} INFO - Job 3242: Subtask scrape_teams_25-30
[2023-05-08T23:48:25.304+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [running]> on host f41dbfa3d325
[2023-05-08T23:48:25.386+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-08T23:48:25.450+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_25-30
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-08T23:48:25.458+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/helpers.py", line 59, in scrape_and_save
    after = datetime.fromisoformat("{{ execution_date }}")
ValueError: Invalid isoformat string: '{{ execution_date }}'
[2023-05-08T23:48:25.474+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_25-30, execution_date=20220501T000000, start_date=20230508T234825, end_date=20230508T234825
[2023-05-08T23:48:25.488+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 3242 for task scrape_teams_25-30 (Invalid isoformat string: '{{ execution_date }}'; 692)
[2023-05-08T23:48:25.540+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-08T23:48:25.597+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-08T23:51:50.350+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:51:50.364+0000] {taskinstance.py:1090} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [queued]>
[2023-05-08T23:51:50.368+0000] {taskinstance.py:1288} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:51:50.370+0000] {taskinstance.py:1289} INFO - Starting attempt 1 of 1
[2023-05-08T23:51:50.372+0000] {taskinstance.py:1290} INFO - 
--------------------------------------------------------------------------------
[2023-05-08T23:51:50.405+0000] {taskinstance.py:1309} INFO - Executing <Task(PythonOperator): scrape_teams_25-30> on 2022-05-01 00:00:00+00:00
[2023-05-08T23:51:50.415+0000] {standard_task_runner.py:55} INFO - Started process 899 to run task
[2023-05-08T23:51:50.428+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'scrape_and_save_to_csv', 'scrape_teams_25-30', 'scheduled__2022-05-01T00:00:00+00:00', '--job-id', '3283', '--raw', '--subdir', 'DAGS_FOLDER/scrape_and_push_dag.py', '--cfg-path', '/tmp/tmpciyxy6h9']
[2023-05-08T23:51:50.433+0000] {standard_task_runner.py:83} INFO - Job 3283: Subtask scrape_teams_25-30
[2023-05-08T23:51:50.568+0000] {task_command.py:389} INFO - Running <TaskInstance: scrape_and_save_to_csv.scrape_teams_25-30 scheduled__2022-05-01T00:00:00+00:00 [running]> on host f41dbfa3d325
[2023-05-08T23:51:50.615+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:205: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2023-05-08T23:51:50.660+0000] {taskinstance.py:1518} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=scrape_and_save_to_csv
AIRFLOW_CTX_TASK_ID=scrape_teams_25-30
AIRFLOW_CTX_EXECUTION_DATE=2022-05-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-05-01T00:00:00+00:00
[2023-05-08T23:52:07.080+0000] {helpers.py:94} INFO - Portland Trail Blazers: Successfully scraped!
[2023-05-08T23:52:24.413+0000] {helpers.py:94} INFO - Sacramento Kings: Successfully scraped!
[2023-05-08T23:52:40.734+0000] {helpers.py:94} INFO - San Antonio Spurs: Successfully scraped!
[2023-05-08T23:52:56.113+0000] {helpers.py:94} INFO - Toronto Raptors: Successfully scraped!
[2023-05-08T23:53:13.260+0000] {helpers.py:94} INFO - Utah Jazz: Successfully scraped!
[2023-05-08T23:53:28.947+0000] {helpers.py:94} INFO - Washington Wizards: Successfully scraped!
[2023-05-08T23:53:28.963+0000] {helpers.py:110} INFO - Saved in /opt/***/data/output_scrape_teams_25-30.csv
[2023-05-08T23:53:28.965+0000] {python.py:177} INFO - Done. Returned value was:      created_timestamp  ...                                           selftext
0  2023-05-08 21:06:29  ...                                                   
0  2023-05-08 20:49:19  ...  Just stumbled across this quote from Clyde Dre...
0  2023-05-08 20:24:19  ...                                                   
0  2023-05-08 19:12:52  ...                                                   
0  2023-05-08 19:11:26  ...                                                   
..                 ...  ...                                                ...
0  2023-04-10 13:57:37  ...  I'm a maccabi tel aviv fan who tries to keep a...
0  2023-04-10 12:30:12  ...  Welcome to the WEEKLY discussion thread! You c...
0  2023-04-10 01:01:01  ...  with it all in the rear-view, what were your f...
0  2023-04-10 00:44:40  ...                                                   
0  2023-04-09 22:29:14  ...  This time last year I was kinda bummed cause w...

[1495 rows x 7 columns]
[2023-05-08T23:53:28.985+0000] {xcom.py:635} ERROR - Object of type DataFrame is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config or make sure to decorate your object with attr.
[2023-05-08T23:53:28.987+0000] {taskinstance.py:1776} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2305, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 240, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 627, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
  File "/usr/local/lib/python3.7/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 176, in encode
    return super().encode(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/json.py", line 170, in default
    return super().default(o)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2023-05-08T23:53:28.996+0000] {taskinstance.py:1332} INFO - Marking task as FAILED. dag_id=scrape_and_save_to_csv, task_id=scrape_teams_25-30, execution_date=20220501T000000, start_date=20230508T235150, end_date=20230508T235328
[2023-05-08T23:53:29.006+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 3283 for task scrape_teams_25-30 (Object of type DataFrame is not JSON serializable; 899)
[2023-05-08T23:53:29.039+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-05-08T23:53:29.061+0000] {taskinstance.py:2596} INFO - 0 downstream tasks scheduled from follow-on schedule check
